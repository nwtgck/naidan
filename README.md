# LM Web UI

> [!NOTE]
> Most of this codebase was generated by Gemini with significantly less human review than usual.

A privacy-focused web interface for LLMs (OpenAI-compatible APIs and Ollama) designed to **run directly from a portable directory** on your filesystem. No servers, no installation—just open and chat.

## Philosophy: Why `file:///`?

The core mission of this project is **radical privacy through minimal trust**. 

In security, the strongest defense is to minimize the number of entities you must rely on. While developers are comfortable with commands like `python -m http.server`, `npx serve`, or deploying Docker containers like Open WebUI, every background server process is an opaque layer. Without careful auditing, a server process could potentially communicate over the network unexpectedly. To us, **true serverless means no server process at all**—not in the cloud, and not even on your local machine.

By supporting the `file:///` protocol, we achieve true accessibility and security:
- **Minimal Trust Model**: Security is transparent. You only need to trust your browser and the code within the HTML file itself. There are no opaque background server processes to audit or manage.
- **Zero Configuration**: No server setup, no command line, and no environment to manage. It is the ultimate portable application.
- **Freedom from Port Friction**: Ports are arbitrary numbers, difficult to associate with specific apps, and prone to collisions. By bypassing the server layer, we eliminate port management and the frustration of "Address already in use" errors entirely.

This commitment to removing unnecessary layers is the primary reason this tool was developed and remains its most important differentiator from other LLM interfaces.

## Key Features

- **Privacy-First & Fully Local**: Your data never leaves your browser. All conversations are stored locally using OPFS or LocalStorage. Combined with the serverless architecture, it ensures complete data sovereignty.
- **Infinite Branching**: Effortlessly fork or edit any message to create complex, tree-structured conversations without losing context.
- **Intuitive Organization**: Seamlessly manage your chats using a drag-and-drop sidebar with support for custom groups and reordering.
- **Rich Rendering**: First-class support for Markdown, LaTeX mathematical equations (KaTeX), and Mermaid diagrams.
- **Lightweight**: While Open WebUI requires a Docker image exceeding 3GB, this entire application is just a few megabytes. It's built for speed and efficiency.

## Development

If you want to modify the code or build from source:

```bash
npm ci
npm run dev   # Start the development server
npm run build # Generates the optimized output in the dist/ directory
```
